{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying TikTok posts that could be news\n",
    "\n",
    "Author: Jasmine Khuu\n",
    "\n",
    "Amount of posts that contain hashtags from our [list of hashtags](https://docs.google.com/spreadsheets/d/1X6mvIKTQo-AQfER5OFJg7kPVphx4nM3rM67-NnCtGt0/edit#gid=0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/l8vczf6927j5fwpqkhrqflsw0000gn/T/ipykernel_75196/3814924576.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  posts_df['video_description'] = posts_df['video_description'].astype(str)\n",
      "/var/folders/t0/l8vczf6927j5fwpqkhrqflsw0000gn/T/ipykernel_75196/3814924576.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  posts_df['hashtags'] = posts_df['video_description'].apply(extract_hashtags)\n",
      "/var/folders/t0/l8vczf6927j5fwpqkhrqflsw0000gn/T/ipykernel_75196/3814924576.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  posts_df['found_hashtags'] = ''\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_description</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>found_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7293175043465497889</td>\n",
       "      <td>things ex staff said about kpop idols pt 3 #kp...</td>\n",
       "      <td>[kpop, kpopfyp, kpopviral, viral, fyp, kpopfac...</td>\n",
       "      <td>[kpop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7300414739799084321</td>\n",
       "      <td>video funny &amp; cute  #funnyvideos #meme #cute #...</td>\n",
       "      <td>[funnyvideos, meme, cute, fyp, viral, humor, usa]</td>\n",
       "      <td>[usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>7297053362237852970</td>\n",
       "      <td>Number 1 is surprising üò≥üôàüßê #usa #tiktok #histo...</td>\n",
       "      <td>[usa, tiktok, history, fastfood, map, trend, p...</td>\n",
       "      <td>[usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>7311421071389887776</td>\n",
       "      <td>Creepy facts about south korea üá∞üá∑ #seoullife #...</td>\n",
       "      <td>[seoullife, korea, southkorea, seoul, koreatra...</td>\n",
       "      <td>[kdrama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>7305849562822872352</td>\n",
       "      <td>I was on the train at 2 am ü´†ü´† #seoullife #kore...</td>\n",
       "      <td>[seoullife, korea, southkorea, seoul, koreatra...</td>\n",
       "      <td>[kdrama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9297</th>\n",
       "      <td>7.30595E+18</td>\n",
       "      <td>#nyt #nytconnections #newyorktimes</td>\n",
       "      <td>[nyt, nytconnections, newyorktimes]</td>\n",
       "      <td>[nyt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9302</th>\n",
       "      <td>7.3152E+18</td>\n",
       "      <td>Bro did NOT pronounce it correctlyüíÄüíÄüíÄ#fortnite...</td>\n",
       "      <td>[school, baseball, basketball, videoviral, tre...</td>\n",
       "      <td>[football]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9313</th>\n",
       "      <td>7.30217E+18</td>\n",
       "      <td>Do you know why the international date line lo...</td>\n",
       "      <td>[reallifelore, lifelore, education, geography,...</td>\n",
       "      <td>[education]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9322</th>\n",
       "      <td>7.29588E+18</td>\n",
       "      <td>Most hated vs most loved member in kpop groups...</td>\n",
       "      <td>[kpop, kpopfyp, viral, kpopfications, trending]</td>\n",
       "      <td>[kpop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9327</th>\n",
       "      <td>7.29447E+18</td>\n",
       "      <td>-KPOP IDOLS WHO WERE FORCED TO DO SOMETHING BY...</td>\n",
       "      <td>[fyp, kpop, yuna, momo, momoland, bahiyyih, so...</td>\n",
       "      <td>[kpop]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 video_id                                  video_description  \\\n",
       "10    7293175043465497889  things ex staff said about kpop idols pt 3 #kp...   \n",
       "21    7300414739799084321  video funny & cute  #funnyvideos #meme #cute #...   \n",
       "73    7297053362237852970  Number 1 is surprising üò≥üôàüßê #usa #tiktok #histo...   \n",
       "270   7311421071389887776  Creepy facts about south korea üá∞üá∑ #seoullife #...   \n",
       "272   7305849562822872352  I was on the train at 2 am ü´†ü´† #seoullife #kore...   \n",
       "...                   ...                                                ...   \n",
       "9297          7.30595E+18                #nyt #nytconnections #newyorktimes    \n",
       "9302           7.3152E+18  Bro did NOT pronounce it correctlyüíÄüíÄüíÄ#fortnite...   \n",
       "9313          7.30217E+18  Do you know why the international date line lo...   \n",
       "9322          7.29588E+18  Most hated vs most loved member in kpop groups...   \n",
       "9327          7.29447E+18  -KPOP IDOLS WHO WERE FORCED TO DO SOMETHING BY...   \n",
       "\n",
       "                                               hashtags found_hashtags  \n",
       "10    [kpop, kpopfyp, kpopviral, viral, fyp, kpopfac...         [kpop]  \n",
       "21    [funnyvideos, meme, cute, fyp, viral, humor, usa]          [usa]  \n",
       "73    [usa, tiktok, history, fastfood, map, trend, p...          [usa]  \n",
       "270   [seoullife, korea, southkorea, seoul, koreatra...       [kdrama]  \n",
       "272   [seoullife, korea, southkorea, seoul, koreatra...       [kdrama]  \n",
       "...                                                 ...            ...  \n",
       "9297                [nyt, nytconnections, newyorktimes]          [nyt]  \n",
       "9302  [school, baseball, basketball, videoviral, tre...     [football]  \n",
       "9313  [reallifelore, lifelore, education, geography,...    [education]  \n",
       "9322    [kpop, kpopfyp, viral, kpopfications, trending]         [kpop]  \n",
       "9327  [fyp, kpop, yuna, momo, momoland, bahiyyih, so...         [kpop]  \n",
       "\n",
       "[285 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hashtags_df = pd.read_csv('News-related hashtags - 2.csv', dtype=str)\n",
    "results_df = pd.read_csv('results_all.csv', dtype=str)\n",
    "\n",
    "# extract hashtags from dataframe\n",
    "hashtags_list = hashtags_df['Hashtags'].tolist()\n",
    "\n",
    "# extract hashtags from video description\n",
    "def extract_hashtags(description):\n",
    "    hashtags = []\n",
    "    for word in description.split():\n",
    "        if word.startswith('#'):\n",
    "            hashtags.append(word[1:])\n",
    "    return hashtags\n",
    "\n",
    "# create new dataframe\n",
    "posts_df = results_df[['video_id', 'video_description']]\n",
    "posts_df['video_description'] = posts_df['video_description'].astype(str)\n",
    "posts_df['hashtags'] = posts_df['video_description'].apply(extract_hashtags)\n",
    "\n",
    "# new column\n",
    "posts_df['found_hashtags'] = ''\n",
    "\n",
    "for index, row in posts_df.iterrows():\n",
    "    found_hashtags = []\n",
    "    for hashtag in row['hashtags']:\n",
    "        if hashtag in set(hashtags_list): # check if hashtag in list\n",
    "            found_hashtags.append(hashtag)\n",
    "    posts_df.at[index, 'found_hashtags'] = found_hashtags # updating column\n",
    "\n",
    "# filter out rows where no hashtags are found\n",
    "filtered_posts_df = posts_df[posts_df['found_hashtags'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "# save to csv only if if there are found hashtags\n",
    "if not filtered_posts_df.empty:\n",
    "    filtered_posts_df[['video_id', 'found_hashtags', 'video_description']].to_csv('newsposts_data.csv', index=False)\n",
    "\n",
    "filtered_posts_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/l8vczf6927j5fwpqkhrqflsw0000gn/T/ipykernel_75196/3498935130.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  posts_df['found_hashtags'] = ''\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_description</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>found_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.315229e+18</td>\n",
       "      <td>Replying to @ffredinho_23 WIFE‚ÄôS PERSPECTIVE -...</td>\n",
       "      <td>[reddit, redditstories, redditreadings, askred...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.315223e+18</td>\n",
       "      <td>Replying to @connormalloy5 Update - My WIFE ha...</td>\n",
       "      <td>[reddit, redditstories, redditreadings, askred...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.315212e+18</td>\n",
       "      <td>My WIFE has been INSISTING that we have a 3 WA...</td>\n",
       "      <td>[reddit, redditstories, redditreadings, askred...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.315089e+18</td>\n",
       "      <td>ü§∑üèº‚Äç‚ôÄÔ∏èü§∑üèº‚Äç‚ôÄÔ∏è #dateideas #redthoughts #viral #love</td>\n",
       "      <td>[dateideas, redthoughts, viral, love]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.306701e+18</td>\n",
       "      <td>For y'all who always want to see more. We've g...</td>\n",
       "      <td>[greatdane, doggrooming, grossola, fyp„Ç∑, satis...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9325</th>\n",
       "      <td>7.300560e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9326</th>\n",
       "      <td>7.307380e+18</td>\n",
       "      <td>Stay¬†out¬†of¬†the¬†woods #scaryvideos  #skinwalke...</td>\n",
       "      <td>[scaryvideos, skinwalker, scarystories, backro...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9327</th>\n",
       "      <td>7.294470e+18</td>\n",
       "      <td>-KPOP IDOLS WHO WERE FORCED TO DO SOMETHING BY...</td>\n",
       "      <td>[fyp, kpop, yuna, momo, momoland, bahiyyih, so...</td>\n",
       "      <td>[kpop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9328</th>\n",
       "      <td>7.303360e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9329</th>\n",
       "      <td>7.304370e+18</td>\n",
       "      <td>Look closely behind‚Ä¶ #scary #scaryvideos #cree...</td>\n",
       "      <td>[scary, scaryvideos, creepy, horror, paranormal]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9330 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          video_id                                  video_description  \\\n",
       "0     7.315229e+18  Replying to @ffredinho_23 WIFE‚ÄôS PERSPECTIVE -...   \n",
       "1     7.315223e+18  Replying to @connormalloy5 Update - My WIFE ha...   \n",
       "2     7.315212e+18  My WIFE has been INSISTING that we have a 3 WA...   \n",
       "3     7.315089e+18   ü§∑üèº‚Äç‚ôÄÔ∏èü§∑üèº‚Äç‚ôÄÔ∏è #dateideas #redthoughts #viral #love    \n",
       "4     7.306701e+18  For y'all who always want to see more. We've g...   \n",
       "...            ...                                                ...   \n",
       "9325  7.300560e+18                                                nan   \n",
       "9326  7.307380e+18  Stay¬†out¬†of¬†the¬†woods #scaryvideos  #skinwalke...   \n",
       "9327  7.294470e+18  -KPOP IDOLS WHO WERE FORCED TO DO SOMETHING BY...   \n",
       "9328  7.303360e+18                                                nan   \n",
       "9329  7.304370e+18  Look closely behind‚Ä¶ #scary #scaryvideos #cree...   \n",
       "\n",
       "                                               hashtags found_hashtags  \n",
       "0     [reddit, redditstories, redditreadings, askred...             []  \n",
       "1     [reddit, redditstories, redditreadings, askred...             []  \n",
       "2     [reddit, redditstories, redditreadings, askred...             []  \n",
       "3                 [dateideas, redthoughts, viral, love]             []  \n",
       "4     [greatdane, doggrooming, grossola, fyp„Ç∑, satis...             []  \n",
       "...                                                 ...            ...  \n",
       "9325                                                 []             []  \n",
       "9326  [scaryvideos, skinwalker, scarystories, backro...             []  \n",
       "9327  [fyp, kpop, yuna, momo, momoland, bahiyyih, so...         [kpop]  \n",
       "9328                                                 []             []  \n",
       "9329   [scary, scaryvideos, creepy, horror, paranormal]             []  \n",
       "\n",
       "[9330 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a new column to store found hashtags\n",
    "posts_df['found_hashtags'] = ''\n",
    "\n",
    "# Iterate through each row in the 'hashtags' column\n",
    "for index, row in posts_df.iterrows():\n",
    "    found_hashtags = []\n",
    "    # Iterate through each hashtag in the row\n",
    "    for hashtag in row['hashtags']:\n",
    "        # Check if the hashtag is in the hashtags list\n",
    "        if hashtag in set(hashtags_list):\n",
    "            found_hashtags.append(hashtag)\n",
    "    # Update the 'found_hashtags' column with the found hashtags for the current row\n",
    "    posts_df.at[index, 'found_hashtags'] = found_hashtags\n",
    "\n",
    "posts_df[['video_id','found_hashtags','video_description']].to_csv('newsposts_data.csv', index=False)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "posts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/l8vczf6927j5fwpqkhrqflsw0000gn/T/ipykernel_75196/1155948570.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  posts_df['video_description'] = posts_df['video_description'].astype(str)\n",
      "/var/folders/t0/l8vczf6927j5fwpqkhrqflsw0000gn/T/ipykernel_75196/1155948570.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  posts_df['hashtags'] = posts_df['video_description'].apply(extract_hashtags)\n",
      "/var/folders/t0/l8vczf6927j5fwpqkhrqflsw0000gn/T/ipykernel_75196/1155948570.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  posts_df['found_hashtags'] = ''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          video_id                                  video_description  \\\n",
      "10    7.293175e+18  things ex staff said about kpop idols pt 3 #kp...   \n",
      "21    7.300415e+18  video funny & cute  #funnyvideos #meme #cute #...   \n",
      "73    7.297053e+18  Number 1 is surprising üò≥üôàüßê #usa #tiktok #histo...   \n",
      "270   7.311421e+18  Creepy facts about south korea üá∞üá∑ #seoullife #...   \n",
      "272   7.305850e+18  I was on the train at 2 am ü´†ü´† #seoullife #kore...   \n",
      "...            ...                                                ...   \n",
      "9297  7.305950e+18                #nyt #nytconnections #newyorktimes    \n",
      "9302  7.315200e+18  Bro did NOT pronounce it correctlyüíÄüíÄüíÄ#fortnite...   \n",
      "9313  7.302170e+18  Do you know why the international date line lo...   \n",
      "9322  7.295880e+18  Most hated vs most loved member in kpop groups...   \n",
      "9327  7.294470e+18  -KPOP IDOLS WHO WERE FORCED TO DO SOMETHING BY...   \n",
      "\n",
      "                                               hashtags found_hashtags  \n",
      "10    [kpop, kpopfyp, kpopviral, viral, fyp, kpopfac...         [kpop]  \n",
      "21    [funnyvideos, meme, cute, fyp, viral, humor, usa]          [usa]  \n",
      "73    [usa, tiktok, history, fastfood, map, trend, p...          [usa]  \n",
      "270   [seoullife, korea, southkorea, seoul, koreatra...       [kdrama]  \n",
      "272   [seoullife, korea, southkorea, seoul, koreatra...       [kdrama]  \n",
      "...                                                 ...            ...  \n",
      "9297                [nyt, nytconnections, newyorktimes]          [nyt]  \n",
      "9302  [school, baseball, basketball, videoviral, tre...     [football]  \n",
      "9313  [reallifelore, lifelore, education, geography,...    [education]  \n",
      "9322    [kpop, kpopfyp, viral, kpopfications, trending]         [kpop]  \n",
      "9327  [fyp, kpop, yuna, momo, momoland, bahiyyih, so...         [kpop]  \n",
      "\n",
      "[285 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "hashtags_df = pd.read_csv('News-related hashtags - 2.csv')\n",
    "results_df = pd.read_csv('results_all.csv')\n",
    "\n",
    "# Extract hashtags from the hashtags dataframe\n",
    "hashtags_list = hashtags_df['Hashtags'].tolist()\n",
    "\n",
    "# Extract hashtags from video descriptions\n",
    "def extract_hashtags(description):\n",
    "    hashtags = []\n",
    "    for word in description.split():\n",
    "        if word.startswith('#'):\n",
    "            hashtags.append(word[1:])\n",
    "    return hashtags\n",
    "\n",
    "# Create a dataframe for posts\n",
    "posts_df = results_df[['video_id', 'video_description']]\n",
    "posts_df['video_description'] = posts_df['video_description'].astype(str)\n",
    "\n",
    "# Apply the function to create a new column 'hashtags'\n",
    "posts_df['hashtags'] = posts_df['video_description'].apply(extract_hashtags)\n",
    "\n",
    "# Initialize a new column to store found hashtags\n",
    "posts_df['found_hashtags'] = ''\n",
    "\n",
    "# Iterate through each row in the 'hashtags' column\n",
    "for index, row in posts_df.iterrows():\n",
    "    found_hashtags = []\n",
    "    # Iterate through each hashtag in the row\n",
    "    for hashtag in row['hashtags']:\n",
    "        # Check if the hashtag is in the hashtags list\n",
    "        if hashtag in set(hashtags_list):\n",
    "            found_hashtags.append(hashtag)\n",
    "    # Update the 'found_hashtags' column with the found hashtags for the current row\n",
    "    posts_df.at[index, 'found_hashtags'] = found_hashtags\n",
    "\n",
    "# Filter out rows where no hashtags are found\n",
    "filtered_posts_df = posts_df[posts_df['found_hashtags'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "# Save to CSV only if there are found hashtags\n",
    "if not filtered_posts_df.empty:\n",
    "    filtered_posts_df[['video_id', 'found_hashtags', 'video_description']].to_csv('newsbyhashtag_data.csv', index=False)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "print(filtered_posts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
